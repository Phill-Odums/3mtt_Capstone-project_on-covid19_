# importing required libraries
import pandas as pd
import numpy as np
import matplotlib_inline as plt
import matplotlib.pyplot as plt
import seaborn as sns


#importing the dataset 
covid = pd.read_csv("covid_19_clean_complete.csv")


# displaying the information on the dataset 
covid

#using describe  method to check about the dataset 
covid.describe()


#checking count values of dataset using count method
covid.count()

# using value_counts method to check number of occurance   
covid.value_counts()

# checking for number of rows and columns in the dataset using shape method
covid.shape


# checking for category of columns in the dataset
covid.columns


# checking for dublicated information in the dataset 
covid.duplicated().sum()


# checking for empty values in the dataset
covid.isna().sum()


# dropping irrelevant column in the dataset
covid.drop(["Province/State"],axis=1,inplace= True)


# reviewing the dataset if columns has been dropped
covid


# renaming Country/Region column to Country for easy assesing 
covid.rename(columns=  {"Country/Region":"Country"},inplace=True) 


#converting date column to datetime stamp for extraction
covid["Date"] = pd.to_datetime(covid["Date"])



# extracting Month from datetime in numerics for modelling using dt.month
covid["Month"] = covid["Date"].dt.month


# extracting Month from datetime in string for visualization using dt.month_name()
covid["Months"] = covid["Date"].dt.month_name()


# extracting day from datetime in numerics for modelling using dt.day
covid["Day"] = covid["Date"].dt.day


# extracting day from datetime in strings for visualization using dt.day_name
covid["Days"] = covid["Date"].dt.day_name()


# displaying the dataset to check if new features are included
covid


# Merging longitude and latitude columns into a single column
covid['Coordinates'] = covid.apply(lambda row: (row['Lat'], row['Long']), axis=1)


# sorting date in ascending order 
covid["Date"] = covid["Date"].sort_values()

#setting date to index 
covid.set_index("Date",inplace=True)


# sorting country names alphabetically 
covid.sort_values(by="Country",ascending=True,inplace=True)


#sorting countries based on date index
covid.sort_values(by=["Country","Date"],ascending=True,inplace=True)


# displaying dataset to see new added features 
covid


# extracting_daily_growth rate in percentage from the given information in dataset
covid["Daily growth rate"] = ((covid["Confirmed"] - covid["Confirmed"].shift(1))/(covid["Confirmed"].shift(1))*100)


# displaying information to see new features 
covid


# extracting Total_population from the given information in the dataset 
covid["Total_Population"] = (covid["Confirmed"]+covid["Deaths"]+covid["Recovered"]+covid["Active"])



# extracting Mortality_rate from the given information in the dataset
covid["Mortality rate"] = (covid["Deaths"] / covid["Total_Population"])*100 


# displaying the dataset to see the new features 
covid



covid["Daily Recovery"] = (covid["Recovered"] - covid["Recovered"].shift(1))/(covid["Recovered"].shift(1))*100



covid.tail()



covid["Daily Active"] = (covid["Active"] - covid["Active"].shift(1))/(covid["Active"].shift(1))*100


covid.tail()


# grouping confirmed cases per country population using groupby method
case_per_population = covid.groupby("Country")["Confirmed"].sum().reset_index()


# displaying grouped cases base on country 
case_per_population



# grouping countries base on their Regions 
WHO_Regions = covid.groupby("Country")["WHO Region"].sum().reset_index()


# displaying grouped countries base on their regions 
WHO_Regions



# checking for missing values in the dataset 
covid.isna().sum()



# filling missing values with 0 instead of NAN 
covid.fillna({"Daily growth rate":0},inplace=True)
covid["Daily growth rate"]


# checking if missing values are filled
covid.isna().sum()



# filling the missing values with 0  
covid.fillna({"Mortality rate": (int(0))},inplace=True)
covid["Mortality rate"]



#checcking dataset if missing values has been filled 
covid.isna().sum()



# filling the missing values with 0
covid.fillna({"Daily Recovery": (int(0))},inplace=True)
covid.fillna({"Daily Active":   (int(0))},inplace=True) 


covid.isna().sum()


covid.duplicated().sum()


#importing labelEncoder for convertint string values to numerics
from sklearn.preprocessing import LabelEncoder


#creating a new column with converted country and Region to numerics
encorder = LabelEncoder()
covid["EncCountry"] = encorder.fit_transform(covid["Country"]) 
covid["EncWHO Region"] = encorder.fit_transform(covid["WHO Region"]) 


# dropping duplicates 
covid.drop_duplicates(inplace=True)


#checking for duplicated values 
covid.duplicated().sum()



# replace all infinty values with non-numerics and drop all non numerics 
#covid = covid.replace([np.inf, -np.inf], np.nan)dropna()
covid = covid.replace([np.inf, -np.inf], np.nan).fillna(int(0))


#spliting the dataset into train and test 
x = covid[["Long","Lat","Confirmed","Deaths","Recovered","Active",
           "Daily Active","Daily Recovery","Total_Population","Mortality rate","Day","Month","EncWHO Region","EncCountry"]]
y = round(covid["Daily growth rate"])


# checking for the shape of the dataset, number of columns and rows
covid.shape


# converting y and x values to descreate values kusing round function to round up figures
x = np.array((x.round()))
y = np.array((y.round()))

# displaying dataset to see featues 
covid


# importing necessary libraries for assigning splitied values into features and target column for machine learning model 
import sklearn      
from sklearn.model_selection import train_test_split


# assigning splited dataset to test and train
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)



# importing classification model for model building 
from sklearn.tree import DecisionTreeClassifier



#using estimator to improve model performance assigning and assigning to a variable 
model = DecisionTreeClassifier() 

# fitting model 
print(model.fit(x_train,y_train))


# predicting model performance 
y_pred = model.predict(x_test).astype(int)
print(y_pred)


#evaluating model accuracy
from sklearn.metrics import accuracy_score


# printing model accuracy 
accuracy = accuracy_score(y_test,y_pred)
print(f"Model Accuracy: {accuracy:.2f}%")

#importing libraries for evaluating model performance 
from sklearn.metrics import classification_report, accuracy_score, precision_score,confusion_matrix,f1_score,recall_score

# Confusion Matrix
report = confusion_matrix(y_test, y_pred)
print(report)


# Print classification report
print(classification_report(y_test,y_pred))


#printing model precsion score
precision = precision_score(y_test,y_pred,average="weighted")
print(f"precision score : {precision:.4f}")

# printing model F1 score"
F1_score = f1_score(y_test,y_pred,average="weighted")
print(f"F1 Score :{F1_score : 2f}")

#printing model recall score
recall = recall_score(y_test,y_pred, average="micro")
print(f"recall : {recall:.2f} ") 
